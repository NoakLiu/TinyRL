#!/usr/bin/env python3
"""
æœ€å°æ¼”ç¤ºï¼šä½¿ç”¨GPT2å’ŒTinyRLç»„ä»¶

æ¼”ç¤º1ï¼šä¸€ä¸ªLLMåœ¨ä¸€ä¸ªæ²™ç›’é‡Œè¿è¡Œ
æ¼”ç¤º2ï¼šä¸€ä¸ªLLMåŒæ—¶åœ¨ä¸¤ä¸ªæ²™ç›’é‡Œäº¤äº’
"""

import asyncio
import sys
import os
import time

# Add current directory to path for imports
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

class SimpleGPT2:
    """ç®€åŒ–çš„GPT2å®¢æˆ·ç«¯"""
    
    def __init__(self):
        self.model = None
        self._load_model()
    
    def _load_model(self):
        """å»¶è¿ŸåŠ è½½æ¨¡å‹"""
        try:
            from transformers import pipeline
            print("ğŸ“¦ Loading GPT-2 model...")
            self.model = pipeline(
                "text-generation",
                model="gpt2",
                device="cpu",
                max_length=200
            )
            print("âœ… GPT-2 model loaded successfully!")
        except ImportError:
            print("âŒ transformers not installed. Run: pip install torch transformers")
            raise
        except Exception as e:
            print(f"âŒ Failed to load GPT-2: {e}")
            raise
    
    def generate(self, prompt: str) -> str:
        """ç”Ÿæˆæ–‡æœ¬"""
        if not self.model:
            self._load_model()
        
        # ä¸ºä»£ç ç”Ÿæˆä¼˜åŒ–æç¤ºè¯
        if "def " in prompt or "import " in prompt or "class " in prompt:
            enhanced_prompt = f"# Python code\n{prompt}"
        else:
            enhanced_prompt = prompt
        
        outputs = self.model(
            enhanced_prompt,
            max_new_tokens=100,
            temperature=0.7,
            do_sample=True,
            pad_token_id=self.model.tokenizer.eos_token_id,
            num_return_sequences=1
        )
        
        result = outputs[0]["generated_text"]
        # åªè¿”å›æ–°ç”Ÿæˆçš„éƒ¨åˆ†
        if result.startswith(enhanced_prompt):
            result = result[len(enhanced_prompt):].strip()
        
        return result

async def demo1_one_llm_one_sandbox():
    """æ¼”ç¤º1ï¼šä¸€ä¸ªLLMåœ¨ä¸€ä¸ªæ²™ç›’é‡Œè¿è¡Œ"""
    print("\n" + "="*60)
    print("ğŸš€ æ¼”ç¤º1ï¼šä¸€ä¸ªLLMåœ¨ä¸€ä¸ªæ²™ç›’é‡Œè¿è¡Œ")
    print("="*60)
    
    try:
        # å¯¼å…¥æ²™ç›’ç»„ä»¶
        from agents.sandbox import SandboxManager, SandboxConfig
        
        # åˆå§‹åŒ–LLM
        llm = SimpleGPT2()
        
        # åˆ›å»ºæ²™ç›’ç®¡ç†å™¨
        manager = SandboxManager()
        
        # åˆ›å»ºæ²™ç›’é…ç½®
        config = SandboxConfig(
            name="demo_sandbox_1",
            timeout=30,
            max_memory_mb=512
        )
        
        print("ğŸ”§ Creating sandbox...")
        sandbox_id = await manager.create_sandbox(config)
        sandbox = manager.get_sandbox(sandbox_id)
        
        # åˆå§‹åŒ–æ²™ç›’
        await sandbox.initialize()
        print(f"âœ… Sandbox created: {sandbox_id}")
        
        # è®©LLMç”Ÿæˆä»£ç 
        prompt = "def calculate_fibonacci(n):\n    # Calculate fibonacci sequence"
        print(f"\nğŸ“ Prompting LLM: {prompt}")
        
        generated_code = llm.generate(prompt)
        print(f"ğŸ¤– LLM Generated:\n{generated_code}")
        
        # å®Œæ•´çš„ä»£ç 
        full_code = f"""def calculate_fibonacci(n):
    if n <= 1:
        return n
    else:
        return calculate_fibonacci(n-1) + calculate_fibonacci(n-2)

# Test the function
for i in range(10):
    print(f"fibonacci({i}) = {{calculate_fibonacci(i)}}")
"""
        
        print(f"\nğŸ”§ Executing code in sandbox...")
        result = sandbox.execute_code(full_code, "fibonacci.py")
        
        if result.success:
            print(f"âœ… Execution successful!")
            print(f"ğŸ“Š Output:\n{result.output}")
            print(f"â±ï¸ Execution time: {result.execution_time:.2f}s")
        else:
            print(f"âŒ Execution failed:")
            print(f"Error: {result.error}")
        
        # æ¸…ç†
        await manager.destroy_sandbox(sandbox_id)
        print("ğŸ§¹ Sandbox cleaned up")
        
        return result.success
        
    except Exception as e:
        print(f"âŒ Demo 1 failed: {e}")
        return False

async def demo2_one_llm_two_sandboxes():
    """æ¼”ç¤º2ï¼šä¸€ä¸ªLLMåŒæ—¶åœ¨ä¸¤ä¸ªæ²™ç›’é‡Œäº¤äº’"""
    print("\n" + "="*60)
    print("ğŸš€ æ¼”ç¤º2ï¼šä¸€ä¸ªLLMåŒæ—¶åœ¨ä¸¤ä¸ªæ²™ç›’é‡Œäº¤äº’")
    print("="*60)
    
    try:
        # å¯¼å…¥æ²™ç›’ç»„ä»¶
        from agents.sandbox import SandboxManager, SandboxConfig
        
        # åˆå§‹åŒ–LLM
        llm = SimpleGPT2()
        
        # åˆ›å»ºæ²™ç›’ç®¡ç†å™¨
        manager = SandboxManager()
        
        # åˆ›å»ºä¸¤ä¸ªæ²™ç›’é…ç½®
        config1 = SandboxConfig(
            name="data_generator",
            timeout=30,
            max_memory_mb=512
        )
        
        config2 = SandboxConfig(
            name="data_processor", 
            timeout=30,
            max_memory_mb=512
        )
        
        print("ğŸ”§ Creating two sandboxes...")
        sandbox1_id = await manager.create_sandbox(config1)
        sandbox2_id = await manager.create_sandbox(config2)
        
        sandbox1 = manager.get_sandbox(sandbox1_id)
        sandbox2 = manager.get_sandbox(sandbox2_id)
        
        # åˆå§‹åŒ–æ²™ç›’
        await sandbox1.initialize()
        await sandbox2.initialize()
        print(f"âœ… Sandbox 1 (Data Generator): {sandbox1_id}")
        print(f"âœ… Sandbox 2 (Data Processor): {sandbox2_id}")
        
        # ç¬¬ä¸€æ­¥ï¼šåœ¨æ²™ç›’1ä¸­ç”Ÿæˆæ•°æ®
        print(f"\nğŸ“ Step 1: Generate data in Sandbox 1")
        
        data_gen_prompt = "import json\ndata = []"
        print(f"Prompting LLM for data generation...")
        
        # æ•°æ®ç”Ÿæˆä»£ç 
        data_gen_code = """import json
import random

# Generate sample sales data
data = []
for i in range(20):
    sale = {
        'id': i + 1,
        'product': f'Product_{chr(65 + i % 5)}',
        'price': round(random.uniform(10, 100), 2),
        'quantity': random.randint(1, 10),
        'date': f'2024-{random.randint(1, 12):02d}-{random.randint(1, 28):02d}'
    }
    data.append(sale)

# Save to file
with open('sales_data.json', 'w') as f:
    json.dump(data, f, indent=2)

print(f"Generated {len(data)} sales records")
print("Sample data:", data[:3])
"""
        
        print("ğŸ”§ Executing data generation in Sandbox 1...")
        result1 = sandbox1.execute_code(data_gen_code, "generate_data.py")
        
        if result1.success:
            print("âœ… Data generation successful!")
            print(f"ğŸ“Š Output:\n{result1.output}")
        else:
            print(f"âŒ Data generation failed: {result1.error}")
            return False
        
        # ç¬¬äºŒæ­¥ï¼šè¯»å–æ•°æ®æ–‡ä»¶
        try:
            data_content = sandbox1.read_file("sales_data.json")
            print("ğŸ“„ Data file read successfully")
        except Exception as e:
            print(f"âŒ Failed to read data file: {e}")
            return False
        
        # ç¬¬ä¸‰æ­¥ï¼šåœ¨æ²™ç›’2ä¸­å¤„ç†æ•°æ®
        print(f"\nğŸ“ Step 2: Process data in Sandbox 2")
        
        # åœ¨æ²™ç›’2ä¸­å†™å…¥æ•°æ®æ–‡ä»¶
        sandbox2.write_file("sales_data.json", data_content)
        
        # æ•°æ®å¤„ç†ä»£ç 
        data_process_code = """import json

# Load data
with open('sales_data.json', 'r') as f:
    data = json.load(f)

# Process data - calculate statistics
total_sales = sum(item['price'] * item['quantity'] for item in data)
product_counts = {}
for item in data:
    product = item['product']
    product_counts[product] = product_counts.get(product, 0) + item['quantity']

# Generate report
report = {
    'total_records': len(data),
    'total_sales_value': round(total_sales, 2),
    'product_summary': product_counts,
    'average_sale_value': round(total_sales / len(data), 2)
}

# Save report
with open('sales_report.json', 'w') as f:
    json.dump(report, f, indent=2)

print("ğŸ“Š Sales Analysis Report:")
print(f"Total Records: {report['total_records']}")
print(f"Total Sales Value: ${report['total_sales_value']}")
print(f"Average Sale Value: ${report['average_sale_value']}")
print("Product Summary:", report['product_summary'])
"""
        
        print("ğŸ”§ Executing data processing in Sandbox 2...")
        result2 = sandbox2.execute_code(data_process_code, "process_data.py")
        
        if result2.success:
            print("âœ… Data processing successful!")
            print(f"ğŸ“Š Output:\n{result2.output}")
        else:
            print(f"âŒ Data processing failed: {result2.error}")
            return False
        
        # ç¬¬å››æ­¥ï¼šå±•ç¤ºè·¨æ²™ç›’åä½œç»“æœ
        print(f"\nğŸ“ˆ Cross-Sandbox Collaboration Results:")
        print(f"ğŸ“ Files in Sandbox 1: {sandbox1.list_files()}")
        print(f"ğŸ“ Files in Sandbox 2: {sandbox2.list_files()}")
        
        # è¯»å–æœ€ç»ˆæŠ¥å‘Š
        try:
            report_content = sandbox2.read_file("sales_report.json")
            print(f"ğŸ“‹ Final Report Generated:\n{report_content}")
        except Exception as e:
            print(f"âŒ Failed to read report: {e}")
        
        # æ¸…ç†
        await manager.destroy_sandbox(sandbox1_id)
        await manager.destroy_sandbox(sandbox2_id)
        print("ğŸ§¹ Both sandboxes cleaned up")
        
        return True
        
    except Exception as e:
        print(f"âŒ Demo 2 failed: {e}")
        return False

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¤– TinyRL æœ€å°æ¼”ç¤º")
    print("ä½¿ç”¨ GPT-2 + æ²™ç›’ç¯å¢ƒè¿›è¡Œä»£ç æ‰§è¡Œ")
    print("-" * 60)
    
    # æ£€æŸ¥ä¾èµ–
    try:
        import transformers
        print(f"âœ… transformers: {transformers.__version__}")
    except ImportError:
        print("âŒ éœ€è¦å®‰è£…: pip install torch transformers")
        return
    
    # è¿è¡Œæ¼”ç¤º
    results = {}
    
    # æ¼”ç¤º1ï¼šä¸€ä¸ªLLMåœ¨ä¸€ä¸ªæ²™ç›’
    print("\nğŸ¬ Starting Demo 1...")
    results["demo1"] = await demo1_one_llm_one_sandbox()
    
    # ç­‰å¾…ä¸€ä¸‹
    await asyncio.sleep(1)
    
    # æ¼”ç¤º2ï¼šä¸€ä¸ªLLMåœ¨ä¸¤ä¸ªæ²™ç›’
    print("\nğŸ¬ Starting Demo 2...")
    results["demo2"] = await demo2_one_llm_two_sandboxes()
    
    # æ€»ç»“
    print("\n" + "="*60)
    print("ğŸ“Š æ¼”ç¤ºç»“æœæ€»ç»“")
    print("="*60)
    
    success_count = sum(1 for success in results.values() if success)
    total_demos = len(results)
    
    print(f"âœ… æˆåŠŸæ¼”ç¤º: {success_count}/{total_demos}")
    for demo, success in results.items():
        status = "âœ… æˆåŠŸ" if success else "âŒ å¤±è´¥"
        print(f"   {demo}: {status}")
    
    if success_count == total_demos:
        print("\nğŸ‰ æ‰€æœ‰æ¼”ç¤ºéƒ½æˆåŠŸå®Œæˆï¼")
        print("ğŸ’¡ æ‚¨ç°åœ¨å¯ä»¥ä½¿ç”¨å…è´¹çš„GPT-2æ¨¡å‹å’Œæ²™ç›’ç¯å¢ƒå¼€å‘AIåº”ç”¨äº†ï¼")
    else:
        print(f"\nâš ï¸  {total_demos - success_count} ä¸ªæ¼”ç¤ºå¤±è´¥")
        print("ğŸ’¡ è¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯å¹¶ç¡®ä¿ä¾èµ–æ­£ç¡®å®‰è£…")

if __name__ == "__main__":
    # è¿è¡Œæ¼”ç¤º
    asyncio.run(main()) 