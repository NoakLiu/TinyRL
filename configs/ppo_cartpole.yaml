# PPO CartPole Configuration
env:
  name: "CartPole-v1"
  state_dim: 4
  action_dim: 2
  continuous_actions: false

# Network Architecture
network:
  hidden_dim: 256
  attention_type: "hybrid"  # "flash", "linear", "hybrid", null for MLP
  use_attention: true
  
  # Attention parameters
  d_model: 256
  n_heads: 8
  n_layers: 4
  dropout: 0.1
  feature_dim: 64  # for linear attention

# PPO Algorithm
ppo:
  learning_rate: 3e-4
  gamma: 0.99
  gae_lambda: 0.95
  clip_ratio: 0.2
  value_loss_coef: 0.5
  entropy_coef: 0.01
  max_grad_norm: 0.5
  ppo_epochs: 4
  mini_batch_size: 64
  rollout_length: 2048
  
  # Optimizer
  adam_eps: 1e-5
  use_lr_scheduler: false

# Training
training:
  total_timesteps: 100000
  eval_freq: 5000
  save_freq: 10000
  device: "auto"  # "auto", "cuda", "cpu"

# Logging
logging:
  use_wandb: true
  project_name: "tinyrl-cartpole"
  run_name: "ppo-hybrid-attention"
  log_dir: "./logs"
  save_dir: "./checkpoints" 